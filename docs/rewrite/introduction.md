# 引言

## 背景
当前的对话系统在处理单轮对话问题上效果非常好，而在处理多轮或者与上文相关的用户问题时，当前对话系统则表现一般，主要原因是人们的日常对话中每个轮次之间并非孤立的，而是每一轮对话都可能存在指代(pronoun)或者省略(ellipsis)的情况。
这时如果只基于用户当前轮的输入进行回复，则会忽略掉上文的一些重要信息，导致回复的结果不符合上下文语境。

## 问题
Non-Sentential Utterances(NSUs) 表示对话过程中存在省略和指代，且不具备完备语义信息的句子。下表中列举了对话系统中指代和省略造成NSUs的示例：


| 类型 | 示例|
|----|----|
|指代 | A1: 梅西有多高 </br> B1: 官方说他的身高是5英尺7英寸。</br> A2: 他和C罗谁是最好的球员?|
|省略| A1: 你喜欢什么电影? </br> B1: 泰坦尼克。 </br> A2: 为什么呢?|

在指代示例中，A2中的【他】指A1中的【梅西】。

在省略示例中，A2中省略了【喜欢泰坦尼克】。


## 目标
对于 NSUs 问题，改写任务的目标是将最后一句话恢复到具备完整语义信息的句子。在指代示例中，A2恢复到具备完整语义信息的句子，即【梅西和C罗谁是最好的球员？】。在省略示例中，A2恢复到具备完整语义信息的句子，即【你为什么喜欢泰坦尼克？】。


句子恢复到具备完整语义信息后，对话系统的理解模块将其作为输入，无需通过上下文进行建模，便可以准确地理解用户的问题。



## 任务描述

对轮对话 NSUs 的改写问题，可以描述为如下形式：

$$
(H, U_{n} \rightarrow R), H=\{U_{1}, U_{2}, U_{3}, \cdots, U_{n-1}\}
$$

其中： 

- $U_{n}$ 表示在时间 $n$ 时刻的对话文本，属于 NSUs 的输入；
- $H$ 表示在时间 $n$ 之前的会话历史，一共 $n-1$ 轮对话；
- $R$ 表示 $U_{n}$ 经过改写之后得到的文本。

为了保证能为自然语言理解模块提供完整的信息输入，要求改写得到的 $R$ 具备完整的对话历史信息，同事需要保证 $R$ 的流程性和合理性。

改写任务的目标是学习得到的模型 $P(R | (H, U_{n}))$，能够判断是否需要改写，如果需要，则返回噶写后的文本序列。
